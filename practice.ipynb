{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Уже было"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import statistics\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(data):\n",
    "    widthList = []\n",
    "    heightList = []\n",
    "    lengthList = []\n",
    "    volumeList = []\n",
    "    countStacking = 0\n",
    "    countTurnover = 0\n",
    "    boxesCount = 0\n",
    "    for x in data['data_result']['boxes']:\n",
    "        widthList.append(x['size']['width'])\n",
    "        heightList.append(x['size']['height'])\n",
    "        lengthList.append(x['size']['length'])\n",
    "        volumeList.append(x['size']['width']*x['size']['height']*x['size']['length'])\n",
    "        if x['stacking'] == True:\n",
    "            countStacking += 1\n",
    "        if x['turnover'] == True:\n",
    "            countTurnover += 1\n",
    "        boxesCount += 1\n",
    "    meanWidth = statistics.mean(widthList)\n",
    "    meanHeight = statistics.mean(heightList)\n",
    "    meanLength = statistics.mean(lengthList)\n",
    "    meanVolume = statistics.mean(volumeList)\n",
    "\n",
    "    loadingWidth = data['data_result']['cargo_space']['loading_size']['width']\n",
    "    loadingHeight = data['data_result']['cargo_space']['loading_size']['height']\n",
    "    loadingLength = data['data_result']['cargo_space']['loading_size']['length']\n",
    "\n",
    "    density_percent = data['data_result']['cargo_space']['calculation_info']['density_percent']\n",
    "\n",
    "    values = [meanWidth, meanHeight, meanLength, meanVolume, countStacking,\n",
    "              countTurnover, boxesCount, loadingWidth, loadingHeight,\n",
    "              loadingLength, density_percent]\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(param):\n",
    "  field = ['meanWidth','meanHeight','meanLength','meanVolume','countStacking',\n",
    "           'countTurnover', 'boxesCount', 'loadingWidth', 'loadingHeight',\n",
    "           'loadingLength', 'density_percent']\n",
    "  filename = 'data.csv'\n",
    "  with open(filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(field)\n",
    "    writer.writerows(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'ALGORITM/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m folder_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mALGORITM/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m file_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(folder_path)\n\u001b[0;32m      5\u001b[0m param \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m file_list:\n\u001b[0;32m      8\u001b[0m     \u001b[39m# Проверяем, что файл имеет расширение .json\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'ALGORITM/'"
     ]
    }
   ],
   "source": [
    "folder_path = 'ALGORITM/'\n",
    "\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "param = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Проверяем, что файл имеет расширение .json\n",
    "    if file_name.endswith('.json'):\n",
    "        # Формируем полный путь к файлу\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Открываем файл и читаем его содержимое\n",
    "        jsonFile = open(file_path, 'r', encoding='utf-8')\n",
    "        # Загружаем JSON-данные\n",
    "        data = json.load(jsonFile)\n",
    "        new_row = data_preparation(data)\n",
    "        param.append(new_row)\n",
    "        jsonFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запись в файл csv\n",
    "write_to_csv(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пробуем нейронку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "df = pd.read_csv('data.csv') \n",
    "\n",
    "features = df[df.columns[:-1]]\n",
    "targets = df[df.columns[-1]]\n",
    "\n",
    "features = (features - features.mean()) / features.std()\n",
    "\n",
    "features_train, features_val, targets_train, targets_val = train_test_split(features, targets, test_size=0.2)\n",
    "\n",
    "features_train = torch.tensor(features_train.values, dtype=torch.float32)\n",
    "targets_train = torch.tensor(targets_train.values, dtype=torch.float32)\n",
    "\n",
    "features_val = torch.tensor(features_val.values, dtype=torch.float32)\n",
    "targets_val = torch.tensor(targets_val.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TableDataset(features_train, targets_train)\n",
    "val_dataset = TableDataset(features_val, targets_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "num_epochs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss MSE: 6083.5365, RMSE: 77.9970, MAE: 75.7841\n",
      "val Loss MSE: 6218.7180, RMSE: 78.8588, MAE: 76.9303\n",
      "----------\n",
      "train Loss MSE: 6039.8526, RMSE: 77.7165, MAE: 75.5026\n",
      "val Loss MSE: 6142.4205, RMSE: 78.3736, MAE: 76.4330\n",
      "----------\n",
      "train Loss MSE: 5962.0481, RMSE: 77.2143, MAE: 74.9835\n",
      "val Loss MSE: 6046.0091, RMSE: 77.7561, MAE: 75.8021\n",
      "----------\n",
      "train Loss MSE: 5817.0972, RMSE: 76.2699, MAE: 74.0030\n",
      "val Loss MSE: 5810.5299, RMSE: 76.2268, MAE: 74.2175\n",
      "----------\n",
      "train Loss MSE: 5582.5113, RMSE: 74.7162, MAE: 72.3832\n",
      "val Loss MSE: 5511.1446, RMSE: 74.2371, MAE: 72.1561\n",
      "----------\n",
      "train Loss MSE: 5280.0522, RMSE: 72.6640, MAE: 70.2634\n",
      "val Loss MSE: 5196.4891, RMSE: 72.0867, MAE: 69.9484\n",
      "----------\n",
      "train Loss MSE: 4889.2966, RMSE: 69.9235, MAE: 67.3854\n",
      "val Loss MSE: 4800.3162, RMSE: 69.2843, MAE: 67.0783\n",
      "----------\n",
      "train Loss MSE: 4447.3522, RMSE: 66.6885, MAE: 64.0502\n",
      "val Loss MSE: 4307.0031, RMSE: 65.6278, MAE: 63.2921\n",
      "----------\n",
      "train Loss MSE: 3979.6893, RMSE: 63.0848, MAE: 60.2641\n",
      "val Loss MSE: 3809.9290, RMSE: 61.7246, MAE: 59.2245\n",
      "----------\n",
      "train Loss MSE: 3514.9015, RMSE: 59.2866, MAE: 56.3122\n",
      "val Loss MSE: 3365.9144, RMSE: 58.0165, MAE: 55.3748\n",
      "----------\n",
      "train Loss MSE: 3014.2591, RMSE: 54.9023, MAE: 51.7784\n",
      "val Loss MSE: 2849.5562, RMSE: 53.3812, MAE: 50.5821\n",
      "----------\n",
      "train Loss MSE: 2556.7075, RMSE: 50.5639, MAE: 47.2486\n",
      "val Loss MSE: 2382.5602, RMSE: 48.8115, MAE: 45.7857\n",
      "----------\n",
      "train Loss MSE: 2121.7757, RMSE: 46.0627, MAE: 42.4666\n",
      "val Loss MSE: 1934.2964, RMSE: 43.9806, MAE: 40.6717\n",
      "----------\n",
      "train Loss MSE: 1738.5817, RMSE: 41.6963, MAE: 37.9543\n",
      "val Loss MSE: 1596.6433, RMSE: 39.9580, MAE: 36.4249\n",
      "----------\n",
      "train Loss MSE: 1403.1620, RMSE: 37.4588, MAE: 33.5022\n",
      "val Loss MSE: 1291.8693, RMSE: 35.9426, MAE: 32.1905\n",
      "----------\n",
      "train Loss MSE: 1154.9289, RMSE: 33.9842, MAE: 30.0265\n",
      "val Loss MSE: 1027.8686, RMSE: 32.0604, MAE: 28.4064\n",
      "----------\n",
      "train Loss MSE: 944.6156, RMSE: 30.7346, MAE: 26.7646\n",
      "val Loss MSE: 811.5100, RMSE: 28.4870, MAE: 24.9738\n",
      "----------\n",
      "train Loss MSE: 782.6786, RMSE: 27.9764, MAE: 23.9911\n",
      "val Loss MSE: 660.1517, RMSE: 25.6934, MAE: 22.3029\n",
      "----------\n",
      "train Loss MSE: 634.8023, RMSE: 25.1953, MAE: 21.3846\n",
      "val Loss MSE: 544.1705, RMSE: 23.3275, MAE: 20.1732\n",
      "----------\n",
      "train Loss MSE: 548.0507, RMSE: 23.4105, MAE: 19.8135\n",
      "val Loss MSE: 462.4306, RMSE: 21.5042, MAE: 18.5625\n",
      "----------\n",
      "train Loss MSE: 492.7988, RMSE: 22.1991, MAE: 18.5800\n",
      "val Loss MSE: 408.0448, RMSE: 20.2001, MAE: 17.4508\n",
      "----------\n",
      "train Loss MSE: 452.6804, RMSE: 21.2763, MAE: 17.6169\n",
      "val Loss MSE: 373.3402, RMSE: 19.3220, MAE: 16.6399\n",
      "----------\n",
      "train Loss MSE: 437.9032, RMSE: 20.9261, MAE: 17.3383\n",
      "val Loss MSE: 351.7053, RMSE: 18.7538, MAE: 16.0742\n",
      "----------\n",
      "train Loss MSE: 421.5200, RMSE: 20.5310, MAE: 16.9106\n",
      "val Loss MSE: 337.8451, RMSE: 18.3806, MAE: 15.6864\n",
      "----------\n",
      "train Loss MSE: 412.1043, RMSE: 20.3004, MAE: 16.6317\n",
      "val Loss MSE: 323.6427, RMSE: 17.9901, MAE: 15.2156\n",
      "----------\n",
      "train Loss MSE: 409.3865, RMSE: 20.2333, MAE: 16.5374\n",
      "val Loss MSE: 321.0881, RMSE: 17.9189, MAE: 15.1527\n",
      "----------\n",
      "train Loss MSE: 394.8490, RMSE: 19.8708, MAE: 16.2346\n",
      "val Loss MSE: 316.3950, RMSE: 17.7875, MAE: 14.8405\n",
      "----------\n",
      "train Loss MSE: 399.8702, RMSE: 19.9968, MAE: 16.2990\n",
      "val Loss MSE: 311.6706, RMSE: 17.6542, MAE: 14.8242\n",
      "----------\n",
      "train Loss MSE: 392.0151, RMSE: 19.7994, MAE: 16.1438\n",
      "val Loss MSE: 307.2159, RMSE: 17.5276, MAE: 14.5783\n",
      "----------\n",
      "train Loss MSE: 399.2277, RMSE: 19.9807, MAE: 16.2529\n",
      "val Loss MSE: 306.0926, RMSE: 17.4955, MAE: 14.6137\n",
      "----------\n",
      "train Loss MSE: 400.9812, RMSE: 20.0245, MAE: 16.3232\n",
      "val Loss MSE: 307.7636, RMSE: 17.5432, MAE: 14.7173\n",
      "----------\n",
      "train Loss MSE: 396.5609, RMSE: 19.9138, MAE: 16.1752\n",
      "val Loss MSE: 307.3831, RMSE: 17.5323, MAE: 14.6017\n",
      "----------\n",
      "train Loss MSE: 401.3969, RMSE: 20.0349, MAE: 16.2324\n",
      "val Loss MSE: 305.8691, RMSE: 17.4891, MAE: 14.5931\n",
      "----------\n",
      "train Loss MSE: 394.1877, RMSE: 19.8542, MAE: 16.1249\n",
      "val Loss MSE: 306.9248, RMSE: 17.5193, MAE: 14.5869\n",
      "----------\n",
      "train Loss MSE: 396.4346, RMSE: 19.9107, MAE: 16.1941\n",
      "val Loss MSE: 306.0445, RMSE: 17.4941, MAE: 14.4725\n",
      "----------\n",
      "train Loss MSE: 399.9544, RMSE: 19.9989, MAE: 16.2140\n",
      "val Loss MSE: 303.7742, RMSE: 17.4291, MAE: 14.4883\n",
      "----------\n",
      "train Loss MSE: 391.0685, RMSE: 19.7755, MAE: 16.0755\n",
      "val Loss MSE: 304.9730, RMSE: 17.4635, MAE: 14.5036\n",
      "----------\n",
      "train Loss MSE: 394.7305, RMSE: 19.8678, MAE: 16.1277\n",
      "val Loss MSE: 306.1183, RMSE: 17.4962, MAE: 14.5975\n",
      "----------\n",
      "train Loss MSE: 394.2166, RMSE: 19.8549, MAE: 16.0425\n",
      "val Loss MSE: 306.3354, RMSE: 17.5024, MAE: 14.6057\n",
      "----------\n",
      "train Loss MSE: 391.8877, RMSE: 19.7962, MAE: 16.1349\n",
      "val Loss MSE: 305.3374, RMSE: 17.4739, MAE: 14.5305\n",
      "----------\n",
      "train Loss MSE: 400.7788, RMSE: 20.0195, MAE: 16.2162\n",
      "val Loss MSE: 306.4417, RMSE: 17.5055, MAE: 14.5869\n",
      "----------\n",
      "train Loss MSE: 402.7016, RMSE: 20.0674, MAE: 16.3043\n",
      "val Loss MSE: 307.6384, RMSE: 17.5396, MAE: 14.5473\n",
      "----------\n",
      "train Loss MSE: 398.4816, RMSE: 19.9620, MAE: 16.1718\n",
      "val Loss MSE: 305.5460, RMSE: 17.4799, MAE: 14.5609\n",
      "----------\n",
      "train Loss MSE: 395.1431, RMSE: 19.8782, MAE: 16.1934\n",
      "val Loss MSE: 306.2613, RMSE: 17.5003, MAE: 14.6052\n",
      "----------\n",
      "train Loss MSE: 401.7850, RMSE: 20.0446, MAE: 16.2006\n",
      "val Loss MSE: 305.2994, RMSE: 17.4728, MAE: 14.5379\n",
      "----------\n",
      "train Loss MSE: 405.9478, RMSE: 20.1481, MAE: 16.3619\n",
      "val Loss MSE: 305.2671, RMSE: 17.4719, MAE: 14.4787\n",
      "----------\n",
      "train Loss MSE: 392.4666, RMSE: 19.8108, MAE: 16.0492\n",
      "val Loss MSE: 305.5969, RMSE: 17.4813, MAE: 14.5443\n",
      "----------\n",
      "train Loss MSE: 389.2205, RMSE: 19.7287, MAE: 16.0835\n",
      "val Loss MSE: 305.3075, RMSE: 17.4731, MAE: 14.5571\n",
      "----------\n",
      "train Loss MSE: 398.9411, RMSE: 19.9735, MAE: 16.1748\n",
      "val Loss MSE: 304.4461, RMSE: 17.4484, MAE: 14.5296\n",
      "----------\n",
      "train Loss MSE: 392.3570, RMSE: 19.8080, MAE: 16.0416\n",
      "val Loss MSE: 305.1702, RMSE: 17.4691, MAE: 14.5684\n",
      "----------\n",
      "train Loss MSE: 392.3355, RMSE: 19.8075, MAE: 16.0735\n",
      "val Loss MSE: 304.6510, RMSE: 17.4543, MAE: 14.5250\n",
      "----------\n",
      "train Loss MSE: 392.4701, RMSE: 19.8109, MAE: 16.0867\n",
      "val Loss MSE: 304.3352, RMSE: 17.4452, MAE: 14.5471\n",
      "----------\n",
      "train Loss MSE: 385.5878, RMSE: 19.6364, MAE: 15.9998\n",
      "val Loss MSE: 303.7428, RMSE: 17.4282, MAE: 14.4509\n",
      "----------\n",
      "train Loss MSE: 393.0575, RMSE: 19.8257, MAE: 16.0409\n",
      "val Loss MSE: 304.3038, RMSE: 17.4443, MAE: 14.5387\n",
      "----------\n",
      "train Loss MSE: 391.9738, RMSE: 19.7983, MAE: 16.0039\n",
      "val Loss MSE: 305.0257, RMSE: 17.4650, MAE: 14.5516\n",
      "----------\n",
      "train Loss MSE: 391.1039, RMSE: 19.7763, MAE: 16.1097\n",
      "val Loss MSE: 304.4323, RMSE: 17.4480, MAE: 14.4279\n",
      "----------\n",
      "train Loss MSE: 395.2012, RMSE: 19.8797, MAE: 16.2225\n",
      "val Loss MSE: 304.5437, RMSE: 17.4512, MAE: 14.4519\n",
      "----------\n",
      "train Loss MSE: 394.8644, RMSE: 19.8712, MAE: 16.0112\n",
      "val Loss MSE: 305.8406, RMSE: 17.4883, MAE: 14.5794\n",
      "----------\n",
      "train Loss MSE: 393.2298, RMSE: 19.8300, MAE: 16.0532\n",
      "val Loss MSE: 305.7995, RMSE: 17.4871, MAE: 14.5679\n",
      "----------\n",
      "train Loss MSE: 385.3645, RMSE: 19.6307, MAE: 15.9822\n",
      "val Loss MSE: 305.1337, RMSE: 17.4681, MAE: 14.5326\n",
      "----------\n",
      "train Loss MSE: 386.9401, RMSE: 19.6708, MAE: 15.9528\n",
      "val Loss MSE: 305.6572, RMSE: 17.4831, MAE: 14.5944\n",
      "----------\n",
      "train Loss MSE: 391.5601, RMSE: 19.7879, MAE: 16.1027\n",
      "val Loss MSE: 302.9275, RMSE: 17.4048, MAE: 14.4579\n",
      "----------\n",
      "train Loss MSE: 395.6159, RMSE: 19.8901, MAE: 16.0047\n",
      "val Loss MSE: 303.9449, RMSE: 17.4340, MAE: 14.5037\n",
      "----------\n",
      "train Loss MSE: 394.2859, RMSE: 19.8566, MAE: 16.0806\n",
      "val Loss MSE: 303.9984, RMSE: 17.4356, MAE: 14.4833\n",
      "----------\n",
      "train Loss MSE: 388.9061, RMSE: 19.7207, MAE: 15.9973\n",
      "val Loss MSE: 305.1516, RMSE: 17.4686, MAE: 14.4997\n",
      "----------\n",
      "train Loss MSE: 382.5536, RMSE: 19.5590, MAE: 15.7811\n",
      "val Loss MSE: 307.2397, RMSE: 17.5283, MAE: 14.6271\n",
      "----------\n",
      "train Loss MSE: 387.3739, RMSE: 19.6818, MAE: 16.0823\n",
      "val Loss MSE: 306.8072, RMSE: 17.5159, MAE: 14.6122\n",
      "----------\n",
      "train Loss MSE: 394.0195, RMSE: 19.8499, MAE: 16.0951\n",
      "val Loss MSE: 305.6894, RMSE: 17.4840, MAE: 14.5590\n",
      "----------\n",
      "train Loss MSE: 381.5845, RMSE: 19.5342, MAE: 15.8293\n",
      "val Loss MSE: 305.7733, RMSE: 17.4864, MAE: 14.5754\n",
      "----------\n",
      "train Loss MSE: 392.3076, RMSE: 19.8068, MAE: 15.9651\n",
      "val Loss MSE: 305.6176, RMSE: 17.4819, MAE: 14.5559\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Инициализация модели, оптимизатора и функции потерь\n",
    "model = RegressionNet(input_dim=10)\n",
    "model = model.to(device)  # Если вы используете GPU\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "mse_criterion = nn.MSELoss()\n",
    "mae_criterion = nn.L1Loss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_mse_loss = 0.0\n",
    "        running_mae_loss = 0.0\n",
    "\n",
    "        for i, (features, targets) in enumerate(dataloaders[phase]):\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "            \n",
    "            # Calculate loss\n",
    "            mse_loss = mse_criterion(outputs, targets)\n",
    "            mae_loss = mae_criterion(outputs, targets)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                mse_loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            running_mse_loss += mse_loss.item()\n",
    "            running_mae_loss += mae_loss.item()\n",
    "        \n",
    "        epoch_mse_loss = running_mse_loss / len(dataloaders[phase])\n",
    "        epoch_mae_loss = running_mae_loss / len(dataloaders[phase])\n",
    "        epoch_rmse_loss = sqrt(epoch_mse_loss)\n",
    "\n",
    "        print(f'{phase} Loss MSE: {epoch_mse_loss:.4f}, RMSE: {epoch_rmse_loss:.4f}, MAE: {epoch_mae_loss:.4f}')\n",
    "    print('-' * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE: 305.6176, RMSE: 17.4819, MAE: 14.5559"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пробуем catboost (туториалы наше все)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['density_percent']]\n",
    "X = df.drop(['density_percent'], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.048042\n",
      "0:\tlearn: 17.8066625\ttotal: 38.9ms\tremaining: 27.2s\n",
      "250:\tlearn: 7.6159134\ttotal: 446ms\tremaining: 798ms\n",
      "500:\tlearn: 4.6055732\ttotal: 797ms\tremaining: 317ms\n",
      "699:\tlearn: 3.3580994\ttotal: 1.09s\tremaining: 0us\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE:  8.226972030473817\n",
      "MSE:  156.41024458238994\n",
      "RMSE:  12.506408140724895\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(random_state=42, iterations=700, verbose=250)\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_valid)\n",
    "print('-'*80)\n",
    "print('MAE: ', mean_absolute_error(y_valid, predictions))\n",
    "print('MSE: ', mean_squared_error(y_valid, predictions))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_valid, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE:  8.226972030473817\n",
    "# MSE:  156.41024458238994\n",
    "# RMSE:  12.506408140724895"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
