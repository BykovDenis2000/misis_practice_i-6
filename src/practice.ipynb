{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Уже было"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import statistics\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(data):\n",
    "    widthList = []\n",
    "    heightList = []\n",
    "    lengthList = []\n",
    "    volumeList = []\n",
    "    countStacking = 0\n",
    "    countTurnover = 0\n",
    "    boxesCount = 0\n",
    "    for x in data['data_result']['boxes']:\n",
    "        widthList.append(x['size']['width'])\n",
    "        heightList.append(x['size']['height'])\n",
    "        lengthList.append(x['size']['length'])\n",
    "        volumeList.append(x['size']['width']*x['size']['height']*x['size']['length'])\n",
    "        if x['stacking'] == True:\n",
    "            countStacking += 1\n",
    "        if x['turnover'] == True:\n",
    "            countTurnover += 1\n",
    "        boxesCount += 1\n",
    "    meanWidth = statistics.mean(widthList)\n",
    "    meanHeight = statistics.mean(heightList)\n",
    "    meanLength = statistics.mean(lengthList)\n",
    "    meanVolume = statistics.mean(volumeList)\n",
    "\n",
    "    loadingWidth = data['data_result']['cargo_space']['loading_size']['width']\n",
    "    loadingHeight = data['data_result']['cargo_space']['loading_size']['height']\n",
    "    loadingLength = data['data_result']['cargo_space']['loading_size']['length']\n",
    "\n",
    "    density_percent = data['data_result']['cargo_space']['calculation_info']['density_percent']\n",
    "\n",
    "    values = [meanWidth, meanHeight, meanLength, meanVolume, countStacking,\n",
    "              countTurnover, boxesCount, loadingWidth, loadingHeight,\n",
    "              loadingLength, density_percent]\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(param):\n",
    "  field = ['meanWidth','meanHeight','meanLength','meanVolume','countStacking',\n",
    "           'countTurnover', 'boxesCount', 'loadingWidth', 'loadingHeight',\n",
    "           'loadingLength', 'density_percent']\n",
    "  filename = 'data.csv'\n",
    "  with open(filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(field)\n",
    "    writer.writerows(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'ALGORITM/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m folder_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mALGORITM/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m file_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(folder_path)\n\u001b[0;32m      5\u001b[0m param \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m file_list:\n\u001b[0;32m      8\u001b[0m     \u001b[39m# Проверяем, что файл имеет расширение .json\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'ALGORITM/'"
     ]
    }
   ],
   "source": [
    "folder_path = 'ALGORITM/'\n",
    "\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "param = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    # Проверяем, что файл имеет расширение .json\n",
    "    if file_name.endswith('.json'):\n",
    "        # Формируем полный путь к файлу\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Открываем файл и читаем его содержимое\n",
    "        jsonFile = open(file_path, 'r', encoding='utf-8')\n",
    "        # Загружаем JSON-данные\n",
    "        data = json.load(jsonFile)\n",
    "        new_row = data_preparation(data)\n",
    "        param.append(new_row)\n",
    "        jsonFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запись в файл csv\n",
    "write_to_csv(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пробуем нейронку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "df = pd.read_csv('data.csv') \n",
    "\n",
    "features = df[df.columns[:-1]]\n",
    "targets = df[df.columns[-1]]\n",
    "\n",
    "features = (features - features.mean()) / features.std()\n",
    "\n",
    "features_train, features_val, targets_train, targets_val = train_test_split(features, targets, test_size=0.2)\n",
    "\n",
    "features_train = torch.tensor(features_train.values, dtype=torch.float32)\n",
    "targets_train = torch.tensor(targets_train.values, dtype=torch.float32)\n",
    "\n",
    "features_val = torch.tensor(features_val.values, dtype=torch.float32)\n",
    "targets_val = torch.tensor(targets_val.values, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TableDataset(features_train, targets_train)\n",
    "val_dataset = TableDataset(features_val, targets_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "num_epochs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss MSE: 6083.5365, RMSE: 77.9970, MAE: 75.7841\n",
      "val Loss MSE: 6218.7180, RMSE: 78.8588, MAE: 76.9303\n",
      "----------\n",
      "train Loss MSE: 6039.8526, RMSE: 77.7165, MAE: 75.5026\n",
      "val Loss MSE: 6142.4205, RMSE: 78.3736, MAE: 76.4330\n",
      "----------\n",
      "train Loss MSE: 5962.0481, RMSE: 77.2143, MAE: 74.9835\n",
      "val Loss MSE: 6046.0091, RMSE: 77.7561, MAE: 75.8021\n",
      "----------\n",
      "train Loss MSE: 5817.0972, RMSE: 76.2699, MAE: 74.0030\n",
      "val Loss MSE: 5810.5299, RMSE: 76.2268, MAE: 74.2175\n",
      "----------\n",
      "train Loss MSE: 5582.5113, RMSE: 74.7162, MAE: 72.3832\n",
      "val Loss MSE: 5511.1446, RMSE: 74.2371, MAE: 72.1561\n",
      "----------\n",
      "train Loss MSE: 5280.0522, RMSE: 72.6640, MAE: 70.2634\n",
      "val Loss MSE: 5196.4891, RMSE: 72.0867, MAE: 69.9484\n",
      "----------\n",
      "train Loss MSE: 4889.2966, RMSE: 69.9235, MAE: 67.3854\n",
      "val Loss MSE: 4800.3162, RMSE: 69.2843, MAE: 67.0783\n",
      "----------\n",
      "train Loss MSE: 4447.3522, RMSE: 66.6885, MAE: 64.0502\n",
      "val Loss MSE: 4307.0031, RMSE: 65.6278, MAE: 63.2921\n",
      "----------\n",
      "train Loss MSE: 3979.6893, RMSE: 63.0848, MAE: 60.2641\n",
      "val Loss MSE: 3809.9290, RMSE: 61.7246, MAE: 59.2245\n",
      "----------\n",
      "train Loss MSE: 3514.9015, RMSE: 59.2866, MAE: 56.3122\n",
      "val Loss MSE: 3365.9144, RMSE: 58.0165, MAE: 55.3748\n",
      "----------\n",
      "train Loss MSE: 3014.2591, RMSE: 54.9023, MAE: 51.7784\n",
      "val Loss MSE: 2849.5562, RMSE: 53.3812, MAE: 50.5821\n",
      "----------\n",
      "train Loss MSE: 2556.7075, RMSE: 50.5639, MAE: 47.2486\n",
      "val Loss MSE: 2382.5602, RMSE: 48.8115, MAE: 45.7857\n",
      "----------\n",
      "train Loss MSE: 2121.7757, RMSE: 46.0627, MAE: 42.4666\n",
      "val Loss MSE: 1934.2964, RMSE: 43.9806, MAE: 40.6717\n",
      "----------\n",
      "train Loss MSE: 1738.5817, RMSE: 41.6963, MAE: 37.9543\n",
      "val Loss MSE: 1596.6433, RMSE: 39.9580, MAE: 36.4249\n",
      "----------\n",
      "train Loss MSE: 1403.1620, RMSE: 37.4588, MAE: 33.5022\n",
      "val Loss MSE: 1291.8693, RMSE: 35.9426, MAE: 32.1905\n",
      "----------\n",
      "train Loss MSE: 1154.9289, RMSE: 33.9842, MAE: 30.0265\n",
      "val Loss MSE: 1027.8686, RMSE: 32.0604, MAE: 28.4064\n",
      "----------\n",
      "train Loss MSE: 944.6156, RMSE: 30.7346, MAE: 26.7646\n",
      "val Loss MSE: 811.5100, RMSE: 28.4870, MAE: 24.9738\n",
      "----------\n",
      "train Loss MSE: 782.6786, RMSE: 27.9764, MAE: 23.9911\n",
      "val Loss MSE: 660.1517, RMSE: 25.6934, MAE: 22.3029\n",
      "----------\n",
      "train Loss MSE: 634.8023, RMSE: 25.1953, MAE: 21.3846\n",
      "val Loss MSE: 544.1705, RMSE: 23.3275, MAE: 20.1732\n",
      "----------\n",
      "train Loss MSE: 548.0507, RMSE: 23.4105, MAE: 19.8135\n",
      "val Loss MSE: 462.4306, RMSE: 21.5042, MAE: 18.5625\n",
      "----------\n",
      "train Loss MSE: 492.7988, RMSE: 22.1991, MAE: 18.5800\n",
      "val Loss MSE: 408.0448, RMSE: 20.2001, MAE: 17.4508\n",
      "----------\n",
      "train Loss MSE: 452.6804, RMSE: 21.2763, MAE: 17.6169\n",
      "val Loss MSE: 373.3402, RMSE: 19.3220, MAE: 16.6399\n",
      "----------\n",
      "train Loss MSE: 437.9032, RMSE: 20.9261, MAE: 17.3383\n",
      "val Loss MSE: 351.7053, RMSE: 18.7538, MAE: 16.0742\n",
      "----------\n",
      "train Loss MSE: 421.5200, RMSE: 20.5310, MAE: 16.9106\n",
      "val Loss MSE: 337.8451, RMSE: 18.3806, MAE: 15.6864\n",
      "----------\n",
      "train Loss MSE: 412.1043, RMSE: 20.3004, MAE: 16.6317\n",
      "val Loss MSE: 323.6427, RMSE: 17.9901, MAE: 15.2156\n",
      "----------\n",
      "train Loss MSE: 409.3865, RMSE: 20.2333, MAE: 16.5374\n",
      "val Loss MSE: 321.0881, RMSE: 17.9189, MAE: 15.1527\n",
      "----------\n",
      "train Loss MSE: 394.8490, RMSE: 19.8708, MAE: 16.2346\n",
      "val Loss MSE: 316.3950, RMSE: 17.7875, MAE: 14.8405\n",
      "----------\n",
      "train Loss MSE: 399.8702, RMSE: 19.9968, MAE: 16.2990\n",
      "val Loss MSE: 311.6706, RMSE: 17.6542, MAE: 14.8242\n",
      "----------\n",
      "train Loss MSE: 392.0151, RMSE: 19.7994, MAE: 16.1438\n",
      "val Loss MSE: 307.2159, RMSE: 17.5276, MAE: 14.5783\n",
      "----------\n",
      "train Loss MSE: 399.2277, RMSE: 19.9807, MAE: 16.2529\n",
      "val Loss MSE: 306.0926, RMSE: 17.4955, MAE: 14.6137\n",
      "----------\n",
      "train Loss MSE: 400.9812, RMSE: 20.0245, MAE: 16.3232\n",
      "val Loss MSE: 307.7636, RMSE: 17.5432, MAE: 14.7173\n",
      "----------\n",
      "train Loss MSE: 396.5609, RMSE: 19.9138, MAE: 16.1752\n",
      "val Loss MSE: 307.3831, RMSE: 17.5323, MAE: 14.6017\n",
      "----------\n",
      "train Loss MSE: 401.3969, RMSE: 20.0349, MAE: 16.2324\n",
      "val Loss MSE: 305.8691, RMSE: 17.4891, MAE: 14.5931\n",
      "----------\n",
      "train Loss MSE: 394.1877, RMSE: 19.8542, MAE: 16.1249\n",
      "val Loss MSE: 306.9248, RMSE: 17.5193, MAE: 14.5869\n",
      "----------\n",
      "train Loss MSE: 396.4346, RMSE: 19.9107, MAE: 16.1941\n",
      "val Loss MSE: 306.0445, RMSE: 17.4941, MAE: 14.4725\n",
      "----------\n",
      "train Loss MSE: 399.9544, RMSE: 19.9989, MAE: 16.2140\n",
      "val Loss MSE: 303.7742, RMSE: 17.4291, MAE: 14.4883\n",
      "----------\n",
      "train Loss MSE: 391.0685, RMSE: 19.7755, MAE: 16.0755\n",
      "val Loss MSE: 304.9730, RMSE: 17.4635, MAE: 14.5036\n",
      "----------\n",
      "train Loss MSE: 394.7305, RMSE: 19.8678, MAE: 16.1277\n",
      "val Loss MSE: 306.1183, RMSE: 17.4962, MAE: 14.5975\n",
      "----------\n",
      "train Loss MSE: 394.2166, RMSE: 19.8549, MAE: 16.0425\n",
      "val Loss MSE: 306.3354, RMSE: 17.5024, MAE: 14.6057\n",
      "----------\n",
      "train Loss MSE: 391.8877, RMSE: 19.7962, MAE: 16.1349\n",
      "val Loss MSE: 305.3374, RMSE: 17.4739, MAE: 14.5305\n",
      "----------\n",
      "train Loss MSE: 400.7788, RMSE: 20.0195, MAE: 16.2162\n",
      "val Loss MSE: 306.4417, RMSE: 17.5055, MAE: 14.5869\n",
      "----------\n",
      "train Loss MSE: 402.7016, RMSE: 20.0674, MAE: 16.3043\n",
      "val Loss MSE: 307.6384, RMSE: 17.5396, MAE: 14.5473\n",
      "----------\n",
      "train Loss MSE: 398.4816, RMSE: 19.9620, MAE: 16.1718\n",
      "val Loss MSE: 305.5460, RMSE: 17.4799, MAE: 14.5609\n",
      "----------\n",
      "train Loss MSE: 395.1431, RMSE: 19.8782, MAE: 16.1934\n",
      "val Loss MSE: 306.2613, RMSE: 17.5003, MAE: 14.6052\n",
      "----------\n",
      "train Loss MSE: 401.7850, RMSE: 20.0446, MAE: 16.2006\n",
      "val Loss MSE: 305.2994, RMSE: 17.4728, MAE: 14.5379\n",
      "----------\n",
      "train Loss MSE: 405.9478, RMSE: 20.1481, MAE: 16.3619\n",
      "val Loss MSE: 305.2671, RMSE: 17.4719, MAE: 14.4787\n",
      "----------\n",
      "train Loss MSE: 392.4666, RMSE: 19.8108, MAE: 16.0492\n",
      "val Loss MSE: 305.5969, RMSE: 17.4813, MAE: 14.5443\n",
      "----------\n",
      "train Loss MSE: 389.2205, RMSE: 19.7287, MAE: 16.0835\n",
      "val Loss MSE: 305.3075, RMSE: 17.4731, MAE: 14.5571\n",
      "----------\n",
      "train Loss MSE: 398.9411, RMSE: 19.9735, MAE: 16.1748\n",
      "val Loss MSE: 304.4461, RMSE: 17.4484, MAE: 14.5296\n",
      "----------\n",
      "train Loss MSE: 392.3570, RMSE: 19.8080, MAE: 16.0416\n",
      "val Loss MSE: 305.1702, RMSE: 17.4691, MAE: 14.5684\n",
      "----------\n",
      "train Loss MSE: 392.3355, RMSE: 19.8075, MAE: 16.0735\n",
      "val Loss MSE: 304.6510, RMSE: 17.4543, MAE: 14.5250\n",
      "----------\n",
      "train Loss MSE: 392.4701, RMSE: 19.8109, MAE: 16.0867\n",
      "val Loss MSE: 304.3352, RMSE: 17.4452, MAE: 14.5471\n",
      "----------\n",
      "train Loss MSE: 385.5878, RMSE: 19.6364, MAE: 15.9998\n",
      "val Loss MSE: 303.7428, RMSE: 17.4282, MAE: 14.4509\n",
      "----------\n",
      "train Loss MSE: 393.0575, RMSE: 19.8257, MAE: 16.0409\n",
      "val Loss MSE: 304.3038, RMSE: 17.4443, MAE: 14.5387\n",
      "----------\n",
      "train Loss MSE: 391.9738, RMSE: 19.7983, MAE: 16.0039\n",
      "val Loss MSE: 305.0257, RMSE: 17.4650, MAE: 14.5516\n",
      "----------\n",
      "train Loss MSE: 391.1039, RMSE: 19.7763, MAE: 16.1097\n",
      "val Loss MSE: 304.4323, RMSE: 17.4480, MAE: 14.4279\n",
      "----------\n",
      "train Loss MSE: 395.2012, RMSE: 19.8797, MAE: 16.2225\n",
      "val Loss MSE: 304.5437, RMSE: 17.4512, MAE: 14.4519\n",
      "----------\n",
      "train Loss MSE: 394.8644, RMSE: 19.8712, MAE: 16.0112\n",
      "val Loss MSE: 305.8406, RMSE: 17.4883, MAE: 14.5794\n",
      "----------\n",
      "train Loss MSE: 393.2298, RMSE: 19.8300, MAE: 16.0532\n",
      "val Loss MSE: 305.7995, RMSE: 17.4871, MAE: 14.5679\n",
      "----------\n",
      "train Loss MSE: 385.3645, RMSE: 19.6307, MAE: 15.9822\n",
      "val Loss MSE: 305.1337, RMSE: 17.4681, MAE: 14.5326\n",
      "----------\n",
      "train Loss MSE: 386.9401, RMSE: 19.6708, MAE: 15.9528\n",
      "val Loss MSE: 305.6572, RMSE: 17.4831, MAE: 14.5944\n",
      "----------\n",
      "train Loss MSE: 391.5601, RMSE: 19.7879, MAE: 16.1027\n",
      "val Loss MSE: 302.9275, RMSE: 17.4048, MAE: 14.4579\n",
      "----------\n",
      "train Loss MSE: 395.6159, RMSE: 19.8901, MAE: 16.0047\n",
      "val Loss MSE: 303.9449, RMSE: 17.4340, MAE: 14.5037\n",
      "----------\n",
      "train Loss MSE: 394.2859, RMSE: 19.8566, MAE: 16.0806\n",
      "val Loss MSE: 303.9984, RMSE: 17.4356, MAE: 14.4833\n",
      "----------\n",
      "train Loss MSE: 388.9061, RMSE: 19.7207, MAE: 15.9973\n",
      "val Loss MSE: 305.1516, RMSE: 17.4686, MAE: 14.4997\n",
      "----------\n",
      "train Loss MSE: 382.5536, RMSE: 19.5590, MAE: 15.7811\n",
      "val Loss MSE: 307.2397, RMSE: 17.5283, MAE: 14.6271\n",
      "----------\n",
      "train Loss MSE: 387.3739, RMSE: 19.6818, MAE: 16.0823\n",
      "val Loss MSE: 306.8072, RMSE: 17.5159, MAE: 14.6122\n",
      "----------\n",
      "train Loss MSE: 394.0195, RMSE: 19.8499, MAE: 16.0951\n",
      "val Loss MSE: 305.6894, RMSE: 17.4840, MAE: 14.5590\n",
      "----------\n",
      "train Loss MSE: 381.5845, RMSE: 19.5342, MAE: 15.8293\n",
      "val Loss MSE: 305.7733, RMSE: 17.4864, MAE: 14.5754\n",
      "----------\n",
      "train Loss MSE: 392.3076, RMSE: 19.8068, MAE: 15.9651\n",
      "val Loss MSE: 305.6176, RMSE: 17.4819, MAE: 14.5559\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Инициализация модели, оптимизатора и функции потерь\n",
    "model = RegressionNet(input_dim=10)\n",
    "model = model.to(device)  # Если вы используете GPU\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "mse_criterion = nn.MSELoss()\n",
    "mae_criterion = nn.L1Loss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_mse_loss = 0.0\n",
    "        running_mae_loss = 0.0\n",
    "\n",
    "        for i, (features, targets) in enumerate(dataloaders[phase]):\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "            \n",
    "            # Calculate loss\n",
    "            mse_loss = mse_criterion(outputs, targets)\n",
    "            mae_loss = mae_criterion(outputs, targets)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                mse_loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            running_mse_loss += mse_loss.item()\n",
    "            running_mae_loss += mae_loss.item()\n",
    "        \n",
    "        epoch_mse_loss = running_mse_loss / len(dataloaders[phase])\n",
    "        epoch_mae_loss = running_mae_loss / len(dataloaders[phase])\n",
    "        epoch_rmse_loss = sqrt(epoch_mse_loss)\n",
    "\n",
    "        print(f'{phase} Loss MSE: {epoch_mse_loss:.4f}, RMSE: {epoch_rmse_loss:.4f}, MAE: {epoch_mae_loss:.4f}')\n",
    "    print('-' * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE: 305.6176, RMSE: 17.4819, MAE: 14.5559"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пробуем catboost (туториалы наше все)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['density_percent']]\n",
    "X = df.drop(['density_percent'], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, shuffle=True, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mhist(y);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.048042\n",
      "0:\tlearn: 17.8066625\ttotal: 38.9ms\tremaining: 27.2s\n",
      "250:\tlearn: 7.6159134\ttotal: 446ms\tremaining: 798ms\n",
      "500:\tlearn: 4.6055732\ttotal: 797ms\tremaining: 317ms\n",
      "699:\tlearn: 3.3580994\ttotal: 1.09s\tremaining: 0us\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE:  8.226972030473817\n",
      "MSE:  156.41024458238994\n",
      "RMSE:  12.506408140724895\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(random_state=42, iterations=700, verbose=250)\n",
    "# model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_valid)\n",
    "print('-'*80)\n",
    "print('MAE: ', mean_absolute_error(y_valid, predictions))\n",
    "print('MSE: ', mean_squared_error(y_valid, predictions))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_valid, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE:  8.226972030473817\n",
    "# MSE:  156.41024458238994\n",
    "# RMSE:  12.506408140724895"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
